 python模块subprocess学习
    从Python 2.4开始，Python引入subprocess模块来管理子进程，以取代一些旧模块的方法：如os.system、os.spawn、
os.popen*、popen2.*、commands.*不但可以调用外部的命令作为子进程，而且可以连接到子进程的input/utput/error管道，获取相关的返回信息
　　subprocess是python创建子进程的工具，其实和c中的fork出一个子进程，然后在子进程中运行exec执行另外一个进程很类似。
像Linux进程那样，一个进程可以fork一个子进程，并让这个子进程exec另外一个程序。在Python中，我们通过标准库中的subprocess包来fork一个子进程，并运行一个外部的程序。
　　subprocess包中有很多方法创建子进程，这些函数创建子进程的行为不太一样，我们可以根据需求选择不同的方式来创建子进程。另外subprocess还提供了一些管理标准流(standard stream)和管道(pipe)的工具，从而在进程间使用文本通信。

　　使用subprocess包中的函数创建子进程的时候，要注意:
　　1) 在创建子进程之后，父进程是否暂停，并等待子进程运行。
　　2) 函数返回什么
　　3) 当returncode不为0时，父进程如何处理。

　　subprocess.call()
　　父进程等待子进程完成
　　返回退出信息(returncode，相当于exit code，见Linux进程基础)

　　subprocess.check_call()
　　父进程等待子进程完成
　　返回0
　　检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性，可用try...except...来检查(见Python错误处理)。

　　subprocess.check_output()
　　父进程等待子进程完成
　　返回子进程向标准输出的输出结果
　　检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性和output属性，output属性为标准输出的输出结果，可用try...except...来检查。

　　


#include <iostream>
#include <unistd.h>
using namespace std;
 
int main(int argc, const char *argv[])
{
    cout << "Python is powerful" << endl;
    for (int i = 0; i < argc; i++)  
    {   
        cout << argv[i] << endl;  
    }   
    sleep(10);    
    return 0;  
}  


#!/usr/bin/env python
import subprocess

returnCode = subprocess.call('ls -l',shell=True)  
//我们使用了shell=True这个参数。这个时候，我们使用一整个字符串，而不是一个表来运行子进程。Python将先运行一个shell，再用这个shell来解释这整个字符串。
print "returnCode:",returnCode

returnCode = subprocess.call(['ls','-l'])
//我们将程序名(ls)和所带的参数(-l)一起放在一个表中传递给subprocess.call()
print "returnCode:",returnCode

returnCode = subprocess.call(['./app','-a','-b','-c','-d']) 
//app也将参数和app本身以一个列表为传递过去
print "returnCode:",returnCode


yca@ubuntu:~/Desktop/go$ ./assert.py 
total 1256
-rwxr-xr-x 1 yca yca    7785 2013-05-07 20:02 app
-rw-r--r-- 1 yca yca     221 2013-05-07 20:01 app.cpp
-rwxr-xr-x 1 yca yca     217 2013-05-07 20:40 assert.py
-rwxr-xr-x 1 yca yca 1256270 2013-04-28 02:30 hello
-rw-r--r-- 1 yca yca     396 2013-05-01 19:59 hello.go
-rw-r--r-- 1 yca yca     918 2013-05-07 01:08 HelloWorld.go
-rw-r--r-- 1 yca yca     556 2013-05-07 02:43 map.go
returnCode: 0
Python is powerful
./app
-a
-b
-c
-d
returnCode: 0

shell默认为False，在Linux下，shell=False时, Popen调用os.execvp()执行args指定的程序；shell=True时，如果args是字符串，Popen直接调用系统的Shell来执行args指定的程序，如果args是一个序列，则args的第一项是定义程序命令字符串，其它项是调用系统Shell时的附加参数。
在Windows下，不论shell的值如何，Popen调用CreateProcess()执行args指定的外部程序。如果args是一个序列，则先用list2cmdline()转化为字符串，但需要注意的是，并不是MS Windows下所有的程序都可以用list2cmdline来转化为命令行字符串。
 
    subprocess.Popen()
　上面三个函数都是对subprocess.Popen的封装，这些封装的目的是为了让我们容易使用子进程。当我们想要更个性化我们的需求的时候，就要转向Popen类，该类生成的对象用来代表子进程。

class Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0)

　　与上面的封装不同，Popen对象创建后，主程序不会自动等待子进程完成。我们必须调用对象的wait()方法，父进程才会等待 (也就是阻塞block)：


#!/usr/bin/env python
import subprocess
 
child = subprocess.Popen(['./app','-a','-b','-c','-d'])
print "parent process"

yca@ubuntu:~/Desktop/go$ ./assert.py 
parent process
yca@ubuntu:~/Desktop/go$ Python is powerful
./app
-a
-b
-c
-d


从运行结果中看到，父进程在开启子进程之后并没有等待child的完成，而是直接运行print。
#!/usr/bin/env python
import subprocess

child = subprocess.Popen(['./app','-a','-b','-c','-d'])
returnCode = child.wait()
print "returnCode:",returnCode
print "parent process"

yca@ubuntu:~/Desktop/go$ ./assert.py 
Python is powerful
./app
-a
-b
-c
-d
returnCode:0
parent process


很明显父进程在等待子进程执行完毕，才开始执行
此外，你还可以在父进程中对子进程进行其它操作，比如我们上面例子中的child对象:
child.poll()           # 检查子进程状态
child.kill()           # 终止子进程
child.send_signal()    # 向子进程发送信号
child.terminate()      # 终止子进程
子进程的PID存储在child.pid
 

Popen对象
Popen对象有以下方法：
1.Popen.poll()：用于检查子进程是否已经结束。设置并返回returncode属性。
2.Popen.wait()：等待子进程结束。设置并返回returncode属性。
3.Popen.communicate(input=None)：与子进程进行交互。向stdin发送数据，或从stdout和stderr中读取数据。可选参数input指定发送到子进程的参数。Communicate()返回一个元组：(stdoutdata, stderrdata)。注意：如果希望通过进程的stdin向其发送数据，在创建Popen对象的时候，参数stdin必须被设置为PIPE。同样，如果希望从stdout和stderr获取数据，必须将stdout和stderr设置为PIPE。
4.Popen.send_signal(signal)：向子进程发送信号。
注意：windows下目前只支持发送SIGTERM，等效于下面的terminate()
5.Popen.terminate()：停止(stop)子进程。在windows平台下，该方法将调用Windows API TerminateProcess（）来结束子进程。Posix下是发送SIGTERM信号
6.Popen.kill()：杀死子进程。Posix下是发送SIGKILL信号。windows下和terminate()无异。
7.Popen.stdin：如果在创建Popen对象是，参数stdin被设置为PIPE，Popen.stdin将返回一个文件对象用于策子进程发送指令。否则返回None。如果stdin参数是PIPE，此属性就是一个文件对象，否则为None
8.Popen.stdout：如果在创建Popen对象是，参数stdout被设置为PIPE，Popen.stdout将返回一个文件对象用于策子进程发送指令。否则返回None。如果stdout参数是PIPE，此属性就是一个文件对象，否则为None。
9.Popen.stderr：如果在创建Popen对象是，参数stdout被设置为PIPE，Popen.stdout将返回一个文件对象用于策子进程发送指令。否则返回None。如果stderr参数是PIPE，此属性就是一个文件对象，否则为None。
10.Popen.pid：获取子进程的进程ID。注意，如果shell参数为True，这属性指的是子shell的进程号。
11.Popen.returncode：获取进程的返回值。子程序的返回值，由poll()或者wait()设置，间接地也由communicate()设置。如果进程还没有结束，返回None。如果为负数-N的话，表示子进程被N号信号终止。（仅限*nux）。
12.subprocess.call(*popenargs, **kwargs)：运行命令。该函数将一直等待到子进程运行结束，并返回进程的returncode。文章一开始的例子就演示了call函数。如果子进程不需要进行交互,就可以使用该函数来创建。
13.subprocess.check_call(*popenargs, **kwargs)：与subprocess.call(*popenargs, **kwargs)功能一样，只是如果子进程返回的returncode不为0的话，将触发CalledProcessError异常。在异常对象中，包括进程的returncode信息。


注意：如果子进程输出了大量数据到stdout或者stderr的管道，并达到了系统 pipe的缓存大小的话，子进程会等待父进程读取管道，而父进程此时正wait着的话，将会产生传说中的死锁，后果是非常严重滴。建议使用communicate()来 避免这种情况的发生。
Popen.communicate(input=None)
和子进程交互：发送数据到stdin，并从stdout和stderr读数据，直到收到EOF。等待子进程结束。可选的input如有 有的话，要为字符串类型。
此函数返回一个元组： (stdoutdata, stderrdata) 。
注意，要给子进程的stdin发送数据，则Popen的时候，stdin要为PIPE；同理，要可以收数据的话，stdout或者stderr也要为 PIPE。
注意：读到的数据会被缓存在内存里，所以数据量非常大的时候要小心了。


3. 子进程的文本流控制
(沿用child子进程) 子进程的标准输入，标准输出和标准错误也可以通过如下属性表示:
child.stdin
child.stdout
child.stderr
 

我们可以在Popen()建立子进程的时候改变标准输入、标准输出和标准错误，并可以利用subprocess.PIPE将多个子进程的输入和输出连接在一起，构成管道(pipe):
复制代码

1 #!/usr/bin/env python
2 
3 import subprocess
4 
5 child1 = subprocess.Popen(["ls","-l"], stdout=subprocess.PIPE)
6 child2 = subprocess.Popen(["wc"], stdin=child1.stdout,stdout=subprocess.PIPE)
7 out = child2.communicate()
8 print out 

复制代码

child1.stdout-->subprocess.PIPE

child2.stdin<--subprocess.PIPE        

child2.stdout-->subprocess.PIPE

相当于将child1.stdout-->child2.stdin->child2.stdout->subprocess.PIPE

subprocess.PIPE实际上为文本流提供一个缓存区。child1的stdout将文本输出到缓存区，随后child2的stdin从该PIPE中将文本读取走。child2的输出文本也被存放在PIPE中，直到communicate()方法从PIPE中读取出PIPE中的文本。

要注意的是，communicate()是Popen对象的一个方法，该方法会阻塞父进程，直到子进程完成。

 

我们还可以利用communicate()方法来使用PIPE给子进程输入:

 

1 import subprocess
2 child = subprocess.Popen(["cat"], stdin=subprocess.PIPE)
3 child.communicate("vamei") //()不为空，则写入subprocess.PIPE，为空，则从subprocess.PIPE读取

subprocess.PIPE-->child.stdin

commiuncate相当于写入subprocess.PIPE，然后child从subprocess.PIPE读取

    returnCode

　　执行子进程后的返回值是从何而来呢？通过exit的返回值得到

　　

1 #!/bin/bash
2 
3 echo "hello"
4 exit 1
5 ~             

 

 

 
复制代码

1 #!/usr/bin/env python
2 
3 import subprocess
4 
5 child = subprocess.Popen(["./shell.sh"], stdout=subprocess.PIPE)
6 returnCode = child.wait()
7 print "returnCode:",returnCode
8 stdout = child.communicate()
9 print stdout

复制代码

 

yca@ubuntu:~/Desktop/go$ ./assert.py 
returnCode: 1
('hello\n', None)

python进程类subprocess的一些操作方法例子
投稿：junjie 字体：[增加 减小] 类型：转载
这篇文章主要介绍了python进程类subprocess的一些操作方法例子,本文讲解了Popen、wait、poll、kill、communicate等方法的实际操作例子,需要的朋友可以参考下

subprocess.Popen用来创建子进程。

1）Popen启动新的进程与父进程并行执行，默认父进程不等待新进程结束。

复制代码 代码如下:

def TestPopen():
  import subprocess
  p=subprocess.Popen("dir",shell=True)
  for i in range(250) :
    print ("other things")

2）p.wait函数使得父进程等待新创建的进程运行结束，然后再继续父进程的其他任务。且此时可以在p.returncode中得到新进程的返回值。

复制代码 代码如下:

def TestWait():
  import subprocess
  import datetime
  print (datetime.datetime.now())
  p=subprocess.Popen("sleep 10",shell=True)
  p.wait()
  print (p.returncode)
  print (datetime.datetime.now())

3) p.poll函数可以用来检测新创建的进程是否结束。

复制代码 代码如下:

def TestPoll():
  import subprocess
  import datetime
  import time
  print (datetime.datetime.now())
  p=subprocess.Popen("sleep 10",shell=True)
  t = 1
  while(t <= 5):
    time.sleep(1)
    p.poll()
    print (p.returncode)
    t+=1
  print (datetime.datetime.now())

4) p.kill或p.terminate用来结束创建的新进程，在windows系统上相当于调用TerminateProcess()，在posix系统上相当于发送信号SIGTERM和SIGKILL。

复制代码 代码如下:

def TestKillAndTerminate():
    p=subprocess.Popen("notepad.exe")
    t = 1
    while(t <= 5):
      time.sleep(1)
      t +=1
    p.kill()
    #p.terminate()
    print ("new process was killed")

5) p.communicate可以与新进程交互，但是必须要在popen构造时候将管道重定向。

复制代码 代码如下:

def TestCommunicate():
  import subprocess
  cmd = "dir"
  p=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
  (stdoutdata, stderrdata) = p.communicate()
 
  if p.returncode != 0:
        print (cmd + "error !")
  #defaultly the return stdoutdata is bytes, need convert to str and utf8
  for r in str(stdoutdata,encoding='utf8' ).split("\n"):
    print (r)
  print (p.returncode)


def TestCommunicate2():
  import subprocess
  cmd = "dir"
  #universal_newlines=True, it means by text way to open stdout and stderr
  p = subprocess.Popen(cmd, shell=True, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
  curline = p.stdout.readline()

  while(curline != ""):
        print (curline)
        curline = p.stdout.readline()
  p.wait()
  print (p.returncode)

6) call函数可以认为是对popen和wait的分装，直接对call函数传入要执行的命令行，将命令行的退出code返回。

复制代码 代码如下:

def TestCall():
  retcode = subprocess.call("c:\\test.bat")
  print (retcode)

7）subprocess.getoutput 和 subprocess.getstatusoutput ，基本上等价于subprocess.call函数，但是可以返回output，或者同时返回退出code和output。

但是可惜的是好像不能在windows平台使用，在windows上有如下错误：'{' is not recognized as an internal or external command, operable program or batch file.
复制代码 代码如下:

def TestGetOutput():
  outp = subprocess.getoutput("ls -la")
  print (outp)

def TestGetStatusOutput():
  (status, outp) = subprocess.getstatusoutput('ls -la')
  print (status)
  print (outp)

8）总结

popen的参数，第一个为字符串（或者也可以为多个非命名的参数），表示你要执行的命令和命令的参数；后面的均为命名参数；shell=True,表示你前面的传入的命令将在shell下执行，如果你的命令是个可执行文件或bat，不需要指定此参数；stdout=subprocess.PIPE用来将新进程的输出重定向，stderr=subprocess.STDOUT将新进程的错误输出重定向到stdout，stdin=subprocess.PIPE用来将新进程的输入重定向；universal_newlines=True表示以text的方式打开stdout和stderr。

 其他的不推荐使用的模块：

os.system
os.spawn*
os.popen*
popen2.*
commands.*


 Python中subprocess学习
分类： python脚本 2013-03-15 14:53 20117人阅读 评论(0) 收藏 举报
生命不息奋斗不止！

subprocess的目的就是启动一个新的进程并且与之通信。

subprocess模块中只定义了一个类: Popen。可以使用Popen来创建进程，并与进程进行复杂的交互。它的构造函数如下：

subprocess.Popen(args, bufsize=0, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=False, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0)

参数args可以是字符串或者序列类型（如：list，元组），用于指定进程的可执行文件及其参数。如果是序列类型，第一个元素通常是可执行文件的路径。我们也可以显式的使用executeable参数来指定可执行文件的路径。

参数stdin, stdout, stderr分别表示程序的标准输入、输出、错误句柄。他们可以是PIPE，文件描述符或文件对象，也可以设置为None，表示从父进程继承。

如果参数shell设为true，程序将通过shell来执行。

参数env是字典类型，用于指定子进程的环境变量。如果env = None，子进程的环境变量将从父进程中继承。

subprocess.PIPE

　　在创建Popen对象时，subprocess.PIPE可以初始化stdin, stdout或stderr参数。表示与子进程通信的标准流。

subprocess.STDOUT

　　创建Popen对象时，用于初始化stderr参数，表示将错误通过标准输出流输出。

Popen的方法：

Popen.poll()

　　用于检查子进程是否已经结束。设置并返回returncode属性。

Popen.wait()

　　等待子进程结束。设置并返回returncode属性。

Popen.communicate(input=None)

　　与子进程进行交互。向stdin发送数据，或从stdout和stderr中读取数据。可选参数input指定发送到子进程的参数。Communicate()返回一个元组：(stdoutdata, stderrdata)。注意：如果希望通过进程的stdin向其发送数据，在创建Popen对象的时候，参数stdin必须被设置为PIPE。同样，如果希望从stdout和stderr获取数据，必须将stdout和stderr设置为PIPE。

Popen.send_signal(signal)

　　向子进程发送信号。

Popen.terminate()

　　停止(stop)子进程。在windows平台下，该方法将调用Windows API TerminateProcess（）来结束子进程。

Popen.kill()

　　杀死子进程。

Popen.stdin，Popen.stdout ，Popen.stderr ，官方文档上这么说：

stdin, stdout and stderr specify the executed programs’ standard input, standard output and standard error file handles, respectively. Valid values are PIPE, an existing file descriptor (a positive integer), an existing file object, and None.

Popen.pid

　　获取子进程的进程ID。

Popen.returncode

　　获取进程的返回值。如果进程还没有结束，返回None。

---------------------------------------------------------------

简单的用法：
[python] view plaincopy

    p=subprocess.Popen("dir", shell=True)  
    p.wait()  

shell参数根据你要执行的命令的情况来决定，上面是dir命令，就一定要shell=True了，p.wait()可以得到命令的返回值。

如果上面写成a=p.wait()，a就是returncode。那么输出a的话，有可能就是0【表示执行成功】。

---------------------------------------------------------------------------

进程通讯

如果想得到进程的输出，管道是个很方便的方法，这样：
[python] view plaincopy

    p=subprocess.Popen("dir", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)  
    (stdoutput,erroutput) = p.<span>commu</span>nicate()  

p.communicate会一直等到进程退出，并将标准输出和标准错误输出返回，这样就可以得到子进程的输出了。

再看一个communicate的例子。

上面的例子通过communicate给stdin发送数据，然后使用一个tuple接收命令的执行结果。

------------------------------------------------------------------------

上面，标准输出和标准错误输出是分开的，也可以合并起来，只需要将stderr参数设置为subprocess.STDOUT就可以了，这样子：
[python] view plaincopy

    p=subprocess.Popen("dir", shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)  
    (stdoutput,erroutput) = p.<span>commu</span>nicate()  

如果你想一行行处理子进程的输出，也没有问题：
[python] view plaincopy

    p=subprocess.Popen("dir", shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)  
    while True:  
        buff = p.stdout.readline()  
        if buff == '' and p.poll() != None:  
            break  

------------------------------------------------------

死锁

但是如果你使用了管道，而又不去处理管道的输出，那么小心点，如果子进程输出数据过多，死锁就会发生了，比如下面的用法：
[python] view plaincopy

    p=subprocess.Popen("longprint", shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)  
    p.wait()  

longprint是一个假想的有大量输出的进程，那么在我的xp, Python2.5的环境下，当输出达到4096时，死锁就发生了。当然，如果我们用p.stdout.readline或者p.communicate去清理输出，那么无论输出多少，死锁都是不会发生的。或者我们不使用管道，比如不做重定向，或者重定向到文件，也都是可以避免死锁的。

----------------------------------

subprocess还可以连接起来多个命令来执行。

在shell中我们知道，想要连接多个命令可以使用管道。

在subprocess中，可以使用上一个命令执行的输出结果作为下一次执行的输入。例子如下：

例子中，p2使用了第一次执行命令的结果p1的stdout作为输入数据，然后执行tail命令。

- -------------------

下面是一个更大的例子。用来ping一系列的ip地址，并输出是否这些地址的主机是alive的。代码参考了python unix linux 系统管理指南。
[python] view plaincopy

    #!/usr/bin/env python  
      
    from threading import Thread  
    import subprocess  
    from Queue import Queue  
      
    num_threads=3  
    ips=['127.0.0.1','116.56.148.187']  
    q=Queue()  
    def pingme(i,queue):  
        while True:  
            ip=queue.get()  
            print 'Thread %s pinging %s' %(i,ip)  
            ret=subprocess.call('ping -c 1 %s' % ip,shell=True,stdout=open('/dev/null','w'),stderr=subprocess.STDOUT)  
            if ret==0:  
                print '%s is alive!' %ip  
            elif ret==1:  
                print '%s is down...'%ip  
            queue.task_done()  
      
    #start num_threads threads  
    for i in range(num_threads):  
        t=Thread(target=pingme,args=(i,q))  
        t.setDaemon(True)  
        t.start()  
      
    for ip in ips:  
        q.put(ip)  
    print 'main thread waiting...'  
    q.join();print 'Done'  

在上面代码中使用subprocess的主要好处是，使用多个线程来执行ping命令会节省大量时间。

假设说我们用一个线程来处理，那么每个 ping都要等待前一个结束之后再ping其他地址。那么如果有100个地址，一共需要的时间=100*平均时间。

如果使用多个线程，那么最长执行时间的线程就是整个程序运行的总时间。【时间比单个线程节省多了】

这里要注意一下Queue模块的学习。

pingme函数的执行是这样的：

启动的线程会去执行pingme函数。

pingme函数会检测队列中是否有元素。如果有的话，则取出并执行ping命令。

这个队列是多个线程共享的。所以这里我们不使用列表。【假设在这里我们使用列表，那么需要我们自己来进行同步控制。Queue本身已经通过信号量做了同步控制，节省了我们自己做同步控制的工作=。=】

代码中q的join函数是阻塞当前线程。下面是e文注释

　Queue.join()

　　Blocks until all items in the queue have been gotten and processed(task_done()).

---------------------------------------------

学习Processing模块的时候，遇到了进程的join函数。进程的join函数意思说，等待进程运行结束。与这里的Queue的join有异曲同工之妙啊。processing模块学习的文章在这里